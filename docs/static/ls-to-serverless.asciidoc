[[logstash-to-elasticsearch-serverless]]
=== Sending data to {es-serverless}

When you use Elasticsearch on Elastic Cloud Serverless you don’t need to worry about managing the infrastructure that keeps Elasticsearch distributed and available. These resources are automated on the serverless platform and are designed to scale up and down with your workload.


.{ls} to {serverless-full}
****
You’ll use the {ls} link:logstash-docs-md://lsr/plugins-outputs-elasticsearch.md[{es} output plugin] to send data to {serverless-full}.
Note these differences between {es-serverless} and both {ech} and self-managed {es}:

* Use link:/reference/secure-connection.md#ls-api-keys[**API keys**] to access {serverless-full} from {ls} as it does not support native user authentication.
  Any user-based security settings in your link:logstash-docs-md://lsr/plugins-outputs-elasticsearch.md[{es} output plugin] configuration are ignored and may cause errors.
* {serverless-full} uses **data streams** and link:docs-content://manage-data/lifecycle/data-stream.md[{dlm} ({dlm-init})] instead of {ilm} ({ilm-init}). Any {ilm-init} settings in your link:logstash-docs-md://lsr/plugins-outputs-elasticsearch.md[{es} output plugin] configuration are ignored and may cause errors.
* **{ls} monitoring** is available through the link:https://github.com/elastic/integrations/blob/main/packages/logstash/_dev/build/docs/README.md[{ls} Integration] in link:docs-content://solutions/observability.md[Elastic Observability] on {serverless-full}.

*Known issue for Logstash to Elasticsearch Serverless.* +
The logstash-output-elasticsearch `hosts` setting defaults to port :9200. +
Set the value to port :443 instead.
****

[[connecting-to-elasticsearch-serverless]]
==== Communication between {ls} and {es-serverless} 

link:docs-content://solutions/search/serverless-elasticsearch-get-started.md[{es-serverless}] simplifies safe, secure communication between {ls} and {es}.
When you configure the Elasticsearch output plugin to use link:logstash-docs-md://lsr/plugins-outputs-elasticsearch.md#plugins-outputs-elasticsearch-cloud_id[`cloud_id`] and an link:logstash-docs-md://lsr/plugins-outputs-elasticsearch.md#plugins-outputs-elasticsearch-api_key[`api_key`], no additional SSL configuration is needed.

Example:

* `output {elasticsearch { cloud_id => "<cloud id>" api_key => "<api key>" } }`

Note that the value of the link:logstash-docs-md://lsr/plugins-outputs-elasticsearch.md#plugins-outputs-elasticsearch-api_key[`api_key` option] is in the format `id:api_key`, where `id` and `api_key` are the values returned by the link:https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-security-create-api-key[Create API key API].

[[cloud-id-serverless]]
===== Cloud ID 

{ls} uses the Cloud ID, found in the Elastic Cloud web console, to build the Elasticsearch and Kibana hosts settings. It is a base64 encoded text value of about 120 characters made up of upper and lower case letters and numbers. If you have several Cloud IDs, you can add a label, which is ignored internally, to help you tell them apart. To add a label, prefix your Cloud ID with a label and a `:` separator in this format "<label>:<cloud-id>".

[[api-key-serverless]]
===== API key 

When you create an API key for {ls}, select *Logstash* from the *API key format* dropdown.
This option formats the API key in the correct `id:api_key` format required by {ls}.


[[plugins-serverless]]
==== Using Cloud ID with plugins 

The Elasticsearch input, output, and filter plugins, as well as the Elastic_integration filter plugin, support cloud_id in their configurations.

* link:logstash-docs-md://lsr/plugins-inputs-elasticsearch.md#plugins-inputs-elasticsearch-cloud_id[Elasticsearch input plugin]
* link:logstash-docs-md://lsr/plugins-filters-elasticsearch.md#plugins-filters-elasticsearch-cloud_id[Elasticsearch filter plugin]
* link:logstash-docs-md://lsr/plugins-outputs-elasticsearch.md#plugins-outputs-elasticsearch-cloud_id[Elasticsearch output plugin]
* link:logstash-docs-md://lsr/plugins-filters-elastic_integration.md#plugins-filters-elastic_integration-cloud_id[Elastic_integration filter plugin]

[cpm-serverless]
==== Using {ls} Central Pipeline Management with {es-serverless} 

This setting in the `logstash.yml` config file can help you get set up to use Central Pipeline management in Elastic Cloud:

* `xpack.management.elasticsearch.cloud_id`

You can use the `xpack.management.elasticsearch.cloud_id` setting as an alternative to `xpack.management.elasticsearch.hosts`.
