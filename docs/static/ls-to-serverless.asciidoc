[[logstash-to-elasticsearch-serverless]]
=== Sending data to {es-serverless}

When you use Elasticsearch on Elastic Cloud Serverless you donâ€™t need to worry about managing the infrastructure that keeps Elasticsearch distributed and available. These resources are automated on the serverless platform and are designed to scale up and down with your workload.


.{ls} to {serverless-full}
****
You'll use the {ls} <<plugins-outputs-elasticsearch,{es} output plugin>> to send data to {serverless-full}.
Note these differences between {es-serverless} and both {ech} and self-managed {es}:

* Use <<ls-api-keys,API keys>> to access {serverless-full} from {ls} as it does not support native user authentication.
  Any user-based security settings in your {ls} <<plugins-outputs-elasticsearch,{es} output plugin>> configuration are ignored and may cause errors.
* {serverless-full} uses **data streams** and {ref}/data-stream-lifecycle.html[{dlm} ({dlm-init})] instead of {ilm} ({ilm-init}). Any {ilm-init} settings in your {ls} <<plugins-outputs-elasticsearch,{es} output plugin>> configuration are ignored and may cause errors.
* **{ls} monitoring** is available through the link:https://github.com/elastic/integrations/blob/main/packages/logstash/_dev/build/docs/README.md[{ls} Integration] in {observability-guide}/index.html[Elastic Observability] on {serverless-full}.

*Known issue for Logstash to Elasticsearch Serverless.* +
The logstash-output-elasticsearch `hosts` setting defaults to port :9200. +
Set the value to port :443 instead.
****

[[connecting-to-elasticsearch-serverless]]
==== Communication between {ls} and {es-serverless} 

{es-serverless} simplifies safe, secure communication between {ls} and {es}.
When you configure the Elasticsearch output plugin to use <<plugins-outputs-elasticsearch-cloud_id,`cloud_id`>> and an <<plugins-outputs-elasticsearch-api_key,`api_key`>>, no additional SSL configuration is needed.

Example:

* `output {elasticsearch { cloud_id => "<cloud id>" api_key => "<api key>" } }`

The value of the <<plugins-outputs-elasticsearch-api_key,`api_key` option>> is in the format `id:api_key`, where `id` and `api_key` are the values returned by the link:https://www.elastic.co/docs/api/doc/elasticsearch/operation/operation-security-create-api-key[Create API key API].

[[cloud-id-serverless]]
===== Cloud ID 

{ls} uses the Cloud ID, found in the Elastic Cloud web console, to build the Elasticsearch and Kibana hosts settings. It is a base64 encoded text value of about 120 characters made up of upper and lower case letters and numbers. If you have several Cloud IDs, you can add a label, which is ignored internally, to help you tell them apart. To add a label, prefix your Cloud ID with a label and a `:` separator in this format "<label>:<cloud-id>".

[[api-key-serverless]]
===== API key 

When you create an API key for {ls}, select *Logstash* from the *API key format* dropdown.
This option formats the API key in the correct `id:api_key` format required by {ls}.


[[plugins-serverless]]
==== Using Cloud ID with plugins 

The Elasticsearch input, output, and filter plugins, as well as the Elastic_integration filter plugin, support cloud_id in their configurations.

* <<plugins-inputs-elasticsearch-cloud_id,{es} input plugin Cloud ID option>>
* <<plugins-filters-elasticsearch-cloud_id,{es} filter plugin Cloud ID option>>
* <<plugins-outputs-elasticsearch-cloud_id,{es} output plugin Cloud ID option>>
* <<plugins-filters-elastic_integration-cloud_id,Elastic_integration filter plugin Cloud ID option>>

[cpm-serverless]
==== Using {ls} Central Pipeline Management with {es-serverless} 

This setting in the `logstash.yml` config file can help you get set up to use Central Pipeline management in Elastic Cloud:

* `xpack.management.elasticsearch.cloud_id`

You can use the `xpack.management.elasticsearch.cloud_id` setting as an alternative to `xpack.management.elasticsearch.hosts`.
