[[ls-k8s-quick-start]]
== Quick start

WARNING: This documentation is still in development and may be changed or removed in a future release.

This guide provides a walkthrough of how to set up {ls} to deliver Kubernetes logs to {es}. This will set up a Kubernetes cluster, containing {es}, {kib} to store and visualize the logs,  The logs will be monitored by Filebeat, processed through a Logstash pipeline, and then delivered to the {es} pod in the Kubernetes cluster. This also configures local stack monitoring, using a metricbeat pod to monitoring logstash.

This section includes the following topics:

* <<qs-prerequisites>>
* <<qs-set-up>>
* <<qs-generate-certificate>>
* <<qs-create-elastic-stack>>
* <<qs-view-monitoring-data>>
* <<qs-tidy-up>>
* <<qs-external-elasticsearch>>
* <<qs-learn-more>>

[float]
[[qs-prerequisites]]
=== Prerequisites

Before you start, there are a few things you'll need:

. A running Kubernetes cluster - For local/single node testing we recommend using link:https://minikube.sigs.k8s.io[Minikube], which allows you to easily run a single node Kubernetes cluster on your system. Check the `Get Started!` section for install and set up instructions.
. A link:https://github.com/elastic/logstash/blob/feature/kubernetes/k8s/recipes/logstash-k8s-quickstart.zip[small zip file] of config files - Download and expand this archive into an empty directory on your local system. The files are described in <<sample-configuration-files,Sample configuration files>>.

[float]
[[qs-set-up]]
=== Prepare environment

[float]
[[qs-crd]]
==== Install Elastic CRDs

To make it easy to install other elements of the Elastic stack we will install Elastic custom resource definition (CRD) files, as well as the `elastic-operator` custom controller, which will be used to manage the Elastic resources in your cluster:


[source,sh]
--
kubectl create -f https://download.elastic.co/downloads/eck/2.4.0/crds.yaml
kubectl apply -f https://download.elastic.co/downloads/eck/2.4.0/operator.yaml
--

NOTE: The Elastic CRDs and ECK operator can also be set up using Elastic Helm charts, available at link:https://helm.elastic.co[https://helm.elastic.co].

Check the Kubernetes pods status to confirm that the `elastic-operator` pod is running:


[source,sh]
--
kubectl get pods
--

[source,sh]
--
NAME                 READY   STATUS    RESTARTS      AGE
elastic-operator-0   1/1     Running   4 (12m ago)   13d
--

[float]
[[qs-generate-certificate]]
==== Generate certificate files and create Kubernetes Secret definition

To enable secure communication between the elastic stack components in your Kubernetes cluster, we have provided this sample script to generate the CA certificate files. Details about these files are in <<sample-configuration-files,Sample configuration files>>.

[source,sh]
--
./cert/generate_cert.sh
--

.**Expand to view output**
[%collapsible]
====
[source,sh]
--
Generating RSA private key, 2048 bit long modulus
.......................+++
...........................................................................+++
e is 65537 (0x10001)
Generating RSA private key, 2048 bit long modulus
..............................................+++
.............................................+++
e is 65537 (0x10001)
Signature ok
subject=/C=EU/ST=NA/O=Elastic/CN=ServerHostName
Getting CA Private Key
Generating RSA private key, 2048 bit long modulus
............+++
.......................................................................................................................................+++
e is 65537 (0x10001)
Signature ok
subject=/C=EU/ST=NA/O=Elastic/CN=ClientName
Getting CA Private Key
--

Your `logstash-k8s-qs/cert` folder should now contain a set of certificate files, including `client` certificates for Filebeat and Metricbeat, and `server` certificates for Logstash.

The parent `logstash-k8s-qs` directory also has a new `001-secret.yaml` resources file that stores a hash of the client and server certificates.

image::./images/gs-cert-files.png[generated CA certificate files]

====

[float]
[[qs-create-kubernetes-cluster]]
=== Create Kubernetes Cluster

As part of this configuration, we will be setting up Elastic Stack components and Logstash

[float]
[[qs-create-elastic-stack]]
==== Create Elastic Stack components

Now that your environment and certificates are set up, it's time to create an Elastic Stack. We will be creating:

* Elasticsearch - you know, for search
* Kibana - for data visualization
* Filebeat - to monitor container logs
* Metricbeat - to monitor logstash and send stack monitoring data.

as well as the secret definition containing the keys and certificates we generated earlier.

Run the following command to deploy the example using the sample resources provided:

[source,sh]
--
kubectl apply -f "000-elasticsearch.yaml,001-secret.yaml,005-filebeat.yaml,006-metricbeat.yaml,007-kibana.yaml"
--

The elastic stack resources are created:

[source,sh]
--
elasticsearch.elasticsearch.k8s.elastic.co/demo created
secret/logstash-beats-tls created
beat.beat.k8s.elastic.co/demo created
beat.beat.k8s.elastic.co/demo configured
kibana.kibana.k8s.elastic.co/demo created
--

[source,sh]
--
kubectl get pods
--

The pods are starting up. You may need to wait a minute or two for all of them to be ready.

[source,sh]
--
NAME                                    READY   STATUS    RESTARTS       AGE
demo-beat-filebeat-7f4d97f69f-qkkbl     1/1     Running   0              42s
demo-beat-metricbeat-59f4b68cc7-9zrrn   1/1     Running   0              39s
demo-es-default-0                       1/1     Running   0              41s
demo-kb-d7f585494-vbf6s                 1/1     Running   0              39s
elastic-operator-0                      1/1     Running   4 (164m ago)   13d
--


[float]
[[qs-set-up-logstash]]
==== Set up Logstash

Now we have an elastic stack to communicate with, let's set up Logstash.

When setting up Logstash in Kubernetes, we will typically use <<qs-configmap, ConfigMaps>> to set up Logstash configurations, and our pipeline definitions - see <<ls-k8s-configuration-files, Logstash Configuration files in Kubernetes>> for more details on how to configure Logstash in Kubernetes.


Then, we'll create the <<qs-deployment, deployment definition>> for {ls}, including memory, CPU resources, the container ports, timeout settings, and similar, and the <<qs-service, Service definition>>, opening up ports on the logstash pods to the internal metricbeat (for stack monitoring) and filebeat in this instance

Note that in this example, we will be creating a `Deployment`. Certain Logstash configurations, such as when a persistent queue is required, or certain classes of plugins, should be configured using a `StatefulSet`.

[source,sh]
--
kubectl apply -f "001-configmap.yaml,002-deployment.yaml,003-service.yaml"
--

We should now see the Logstash pod up and running

[source,sh]
--
kubectl get pods
--

The pods are starting up. You may need to wait a minute or two for all of them to be ready.

[source,sh]
--
NAME                                    READY   STATUS    RESTARTS       AGE
demo-beat-filebeat-7f4d97f69f-qkkbl     1/1     Running   0              42s
demo-beat-metricbeat-59f4b68cc7-9zrrn   1/1     Running   0              39s
demo-es-default-0                       1/1     Running   0              41s
demo-kb-d7f585494-vbf6s                 1/1     Running   0              39s
elastic-operator-0                      1/1     Running   4 (164m ago)   13d
logstash-7974b9ccb9-jd5xl               1/1     Running   0              42s
--



[float]
[[qs-view-data]]
=== View your data

First, enable port forwarding for the {kib} service on port `5601`. Open a second shell window and run the following:

[source,sh]
--
kubectl port-forward service/demo-kb-http 5601
--

Then, open up a web browser at address `https://localhost:5601`. Depending on your browser you may need to accept the site certificate.

Log in to {kib} using the `elastic` username and password. To obtain the password, run:

[source,sh]
--
kubectl get secret demo-es-elastic-user -o=jsonpath='{.data.elastic}' | base64 --decode; echo
--

This walkthrough sends two types of date to {es} - kubernetes logs and stack monitoring data

[float]
[[qs-view-k8s-logs]]
==== View your kubernetes logs

The filebeat instance attached to this cluster will send log entries from the `kube-api-server` logs to an index specified in the logstash configuration.

To verify that this data is indeed being sent to {es}

Open the {kib} main menu and select **Management**, then **Dev Tools** , and perform the following query:

[source,http request]
--
GET kube-apiserver-*/_count
--

and you should the count rise as more events are discovered from the apiserver logs

[source,json]
--
{
  "count": 89,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  }
}
--



[float]
[[qs-view-monitoring-data]]
==== View the stack monitoring data

This walkthrough also sends stack monitoring data to the {es} instance:

Open the {kib} main menu and select **Management**, then **Stack Monitoring**.

Select the {ls} **Overview**, and under the **Nodes** tab select the link for the {ls} node.

image::./images/gs-logstash-node-metrics.png[{ls} metrics data in {kib}]

That's it! The Logstash pod metrics data is flowing through {ls} into {es} and {kib}. You can monitor the JVM Heap, CPU Utilization, and System Load data as it updates in real time.

[float]
[[qs-tidy-up]]
=== Tidy up

After finishing with this demo, you can run the following command to remove all of the created resources:
 
[source,sh]
--
kubectl delete service,pods,deployment,configmap,secret,beat,elasticsearch,kibana -l app=logstash-demo
--


[float]
[[qs-next-steps]]
=== Next Steps

[float]
[[qs-external-elasticsearch]]
==== Send logs to an External Elasticsearch


Rather than sending to an elasticsearch cluster in the same Kubernetes cluster as logstash, you may want to send data to an Elastic cloud instance.


[float]
[[qs-send-to-elastic-cloud]]
===== Sending to Elastic Cloud

To connect to Elastic cloud, we will only need the logstash based components - no need to include the `elasticsearch` or `kibana` components from the walkthrough

We will need to amend the `Deployment`/`StatefulSet` to set `CLOUD_ID` and `API_KEY` environment variables with the appropriate value for your cloud instance.

One way to do this is to create a link:https://kubernetes.io/docs/concepts/configuration/secret/[secret] to store `CLOUD_ID` and `API_KEY`:


[source,yaml]
--
apiVersion: v1
kind: Secret
metadata:
  name: ess_secret
type: Opaque
data:
  cloud_id: PENMT1VEX0lEPg== <1>
  password: PEFQSV9LRVk+
--
<1> base64 representation of `cloud_id` and `api_key` for your elastic cloud instance - created by
+
[source,sh]
--
echo -n '<CLOUD_ID>' | base64
echo -n '<API_KEY>' | base64
--


Mount the secrets in the `Deployment`/`StatefulSet`


[source,yaml]
--
env:
  - name: CLOUD_ID
      valueFrom:
        secretKeyRef:
          name: ess_secret
          key: cloud_id
    - name: API_KEY
      valueFrom:
        secretKeyRef:
          name: ess_secret
          key: api_key

--

And we will amend the pipeline definition `ConfigMap` to change the destination of the elasticsearch output to the cloud instance.

[source,yaml]
--
    output {
      elasticsearch {
        cloud_id => "CLOUD_ID"
        api_key => "API_KEY"
        ssl => true
      }
--

[float]
[[qs-scale-logstash]]
==== Scale Logstash with Horizontal Pod Autoscaler

For a simple Logstash setup, without <<ls-k8s-persistent-storage, persistent storage>>, or <<ls-k8s-design-for-plugins, plugins that require the storing of local state>>, we can introduce a simple <<qs-autoscaler, horizontal pod autoscaler>>.

Apply the autoscaler as follows:

[source,bash]
--
kubectl apply -f "004-hpa.yaml"
--

NOTE: When using more than one logstash pod, use the link:https://www.elastic.co/guide/en/beats/metricbeat/current/configuration-autodiscover.html#_kubernetes[autodiscover] features of beats to monitor the different logstash pods, otherwise only one logstash pod will be monitored.

[float]
[[qs-learn-more]]
==== Learn more

Now that you're familiar with how to get a {ls} monitoring setup running in your Kubernetes environment, here are a few suggested next steps:

* <<ls-k8s-design-for-plugins>>
* <<ls-k8s-sizing>>
* <<ls-k8s-secure>>
* <<ls-k8s-stack-monitoring>>

As well, we have a variety of <<ls-k8s-recipes,recipes>> that you can use as templates to configure an environment to match your specific use case.
