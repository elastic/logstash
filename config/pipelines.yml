# List of pipelines to be loaded by Logstash
#
# This document must be a list of dictionaries/hashes, where the keys/values are pipeline settings.
# Default values for omitted settings are read from the `logstash.yml` file.
# When declaring multiple pipelines, each MUST have its own `pipeline.id`.
#
# Example of two pipelines:
#

- pipeline.id: stdin
  pipeline.workers: 1
  pipeline.dead_letter_pipeline: 'print'
  pipeline.batch.size: 1
  config.string: 'input { stdin {  } } filter{ json {source => "message" target => ["the_target"] } sleep { time => 0.1 add_tag => "slept" }if [a] != 0 { mutate { add_tag => ["foo"]}} } output {elasticsearch { cloud_id => "es8:XX" cloud_auth => "elastic:YY" data_stream => false }}'
- pipeline.id: dli
  config.string: 'input { dead_letter_pipeline { }} output { elasticsearch { cloud_id => "es8:XX" cloud_auth => "elastic:YY" data_stream => false index => "logstash_dli"}}'
- pipeline.id: repair
  queue.type: memory
  pipeline.dead_letter_pipeline: 'dli'
  config.string: "input { dead_letter_pipeline { }} filter { json { source => '[event][original]' } mutate { remove_field => 'geoip'}  mutate { remove_field => ['error','message'] add_tag => 'repaired' } } output { elasticsearch  { cloud_id => 'es8:XX' cloud_auth => 'elastic:YY' data_stream => false }}"
- pipeline.id: tcp
  pipeline.workers: 1
  pipeline.dead_letter_pipeline: 'dli'
  config.string: 'input { tcp { port => 2323 }} filter{ json {source => "message" target => ["the_target"] }} output {elasticsearch { cloud_id => "es8:XX" cloud_auth => "elastic:YY" data_stream => false }}'
- pipeline.id: tcp2
  pipeline.workers: 1
  pipeline.dead_letter_pipeline: 'print'
  config.string: 'input { tcp { port => 2324 }} filter{ json {source => "message" target => ["the_target"] } }output {elasticsearch { cloud_id => "es8:XX" cloud_auth => "elastic:YY" data_stream => false }}'
- pipeline.id: print
  pipeline.workers: 1
  config.string: 'input { dead_letter_pipeline {}} output { stdout { codec => rubydebug { metadata => true }}}'
- pipeline.id: tcp_broken
  pipeline.workers: 1
  pipeline.dead_letter_pipeline: 'print'
  config.string: 'input { tcp { port => 2325 codec => json { target => "marget" }}} filter{ split { field => "results" } if [a] > 1 {mutate { add_tag  => "a is big" } } }output {elasticsearch { cloud_id => "es8:XX" cloud_auth => "elastic:YY" data_stream => false }}'
- pipeline.id: tcp_working
  pipeline.workers: 1
  pipeline.dead_letter_pipeline: 'print'
  config.string: 'input { tcp { port => 2326 codec => json { target => "marget" }}} filter{ split { field => "results" } mutate { add_tag  => "a is big" } } output { if [a] > 1 {stdout { codec => rubydebug }}}'

